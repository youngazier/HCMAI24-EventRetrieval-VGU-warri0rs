{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TransNetV2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/soCzech/TransNetV2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/students/ttnhan-cse23/hcmai/support_models/TransNetV2\n"
     ]
    }
   ],
   "source": [
    "%cd ../support_models/TransNetV2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch: Fetching reference refs/heads/master\n"
     ]
    }
   ],
   "source": [
    "!git lfs fetch https://github.com/soCzech/TransNetV2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out LFS objects: 100% (3/3), 36 MB | 0 B/s, done.                      \n"
     ]
    }
   ],
   "source": [
    "!git lfs checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/students/ttnhan-cse23/hcmai/notebook\n"
     ]
    }
   ],
   "source": [
    "%cd ../../notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow=2.1 opencv-python matplotlib ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/students/ttnhan-cse23/hcmai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dictionary to store video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L01': {}}\n",
      "{'L01': {'V001': '/home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V001.mp4', 'V002': '/home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V002.mp4', 'V003': '/home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V003.mp4', 'V004': '/home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V004.mp4', 'V005': '/home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V005.mp4'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "dataset_dir = \"/home/students/ttnhan-cse23/hcmai/dataset\"\n",
    "\n",
    "all_video_paths = dict()\n",
    "\n",
    "for folder in sorted(os.listdir(dataset_dir)):\n",
    "    if folder == \"extracted_frames\" or folder == \"extracted_keyframes_JSON\":\n",
    "        continue\n",
    "    all_video_paths[folder] = dict()\n",
    "print(all_video_paths)\n",
    "\n",
    "for folder in sorted(all_video_paths.keys()):\n",
    "    for video in sorted(os.listdir(os.path.join(dataset_dir, folder))):\n",
    "        video_id = video.replace(\".mp4\", \"\").split(\"_\")[-1]\n",
    "        video_path = f\"{dataset_dir}/{folder}/{video}\"\n",
    "        all_video_paths[folder][video_id] = video_path\n",
    "print(all_video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Using weights from /home/students/ttnhan-cse23/hcmai/support_models/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 01:39:31.468512: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2025-03-12 01:39:31.472301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2995200000 Hz\n",
      "2025-03-12 01:39:31.472927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c3e4a360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-12 01:39:31.472934: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-03-12 01:39:31.472982: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V001.mp4\n",
      "[TransNetV2] Processing video frames 31665/31665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V002.mp4\n",
      "[TransNetV2] Processing video frames 24300/24337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 24337/24337\n",
      "[TransNetV2] Extracting frames from /home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V003.mp4\n",
      "[TransNetV2] Processing video frames 30668/30668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V004.mp4\n",
      "[TransNetV2] Processing video frames 23000/23027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 23027/23027\n",
      "[TransNetV2] Extracting frames from /home/students/ttnhan-cse23/hcmai/dataset/L01/L01_V005.mp4\n",
      "[TransNetV2] Processing video frames 29000/29024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:34<00:00, 114.87s/it]\n",
      " 50%|█████     | 1/2 [09:34<09:34, 574.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 29024/29024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 2/2 [09:34<00:00, 287.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from support_models.TransNetV2.inference.transnetv2 import TransNetV2\n",
    "model = TransNetV2()\n",
    "\n",
    "json_save_dir = \"/home/students/ttnhan-cse23/hcmai/dataset/extracted_keyframes_JSON\"\n",
    "\n",
    "for folder_name, video_paths_dict  in tqdm(all_video_paths.items()):                    # using tqdm for progress bar display\n",
    "    videos_id = sorted(video_paths_dict.keys())\n",
    "    \n",
    "    if not os.path.exists(os.path.join(json_save_dir, folder_name)):\n",
    "        os.makedirs(os.path.join(json_save_dir, folder_name))\n",
    "    \n",
    "    for video_id in tqdm(videos_id):\n",
    "        video_path = video_paths_dict[video_id]\n",
    "        \n",
    "        # Scene Change Detection\n",
    "        _, single_frame_prediction, _ = model.predict_video(video_path)\n",
    "        list_of_scenes = model.predictions_to_scenes(predictions=single_frame_prediction)\n",
    "        \n",
    "        with open(f\"{json_save_dir}/{folder_name}/{video_id}.json\", \"w\") as f:\n",
    "            json.dump(list_of_scenes.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_frames_from_shot(start_idx, end_idx):\n",
    "    '''\n",
    "    intervals = np.linspace(start=start_idx, stop=end_idx, num=n_frames+1).astype(int)\n",
    "    ranges = []\n",
    "    for idx, interv in enumerate(intervals[:-1]):\n",
    "        ranges.append((interv, intervals[idx + 1]))\n",
    "    frame_idxs = [(x[0] + x[1]) // 2 for x in ranges]\n",
    "    '''\n",
    "    middle_idx = (start_idx + end_idx) // 2\n",
    "    frame_idxs = [start_idx, middle_idx, end_idx]\n",
    "    return frame_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:16<00:00, 18.85it/s]\n",
      "100%|██████████| 237/237 [00:13<00:00, 17.72it/s]\n",
      "100%|██████████| 330/330 [00:22<00:00, 14.91it/s]\n",
      "100%|██████████| 236/236 [00:13<00:00, 17.68it/s]\n",
      "100%|██████████| 311/311 [00:21<00:00, 14.37it/s]\n",
      "100%|██████████| 5/5 [01:27<00:00, 17.40s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/students/ttnhan-cse23/hcmai/dataset/extracted_keyframes_JSON/extracted_keyframes_JSON/L01.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/tmp/ipykernel_60036/256210431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mvideo_scene_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{scene_json_dir}/{key}/{video_id}.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_scene_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mvideo_scenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/students/ttnhan-cse23/hcmai/dataset/extracted_keyframes_JSON/extracted_keyframes_JSON/L01.json'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "scene_json_dir = \"/home/students/ttnhan-cse23/hcmai/dataset/extracted_keyframes_JSON\"\n",
    "extracted_keyframes_dir = \"/home/students/ttnhan-cse23/hcmai/dataset/extracted_frames\"\n",
    "\n",
    "for key in all_video_paths.keys():\n",
    "    save_dir = os.path.join(extracted_keyframes_dir, key)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    video_paths_dict = all_video_paths[key]\n",
    "    video_ids = sorted(video_paths_dict.keys())\n",
    "    \n",
    "    for video_id in tqdm(video_ids):\n",
    "        video_path = video_paths_dict[video_id]\n",
    "        video_scene_path = f\"{scene_json_dir}/{key}/{video_id}.json\"\n",
    "        \n",
    "        with open(video_scene_path, \"r\") as f:\n",
    "            video_scenes = json.load(f)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(save_dir, video_id)):\n",
    "            os.mkdir(os.path.join(save_dir, video_id))\n",
    "            \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"❌ Error: Unable to open video {video_path}\")\n",
    "            continue\n",
    "        for i, shot in enumerate(tqdm(video_scenes)):\n",
    "            shot_frames_id = sample_frames_from_shot(shot[0], shot[1])\n",
    "            for index in shot_frames_id:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "                filename = \"{}/{:0>6d}.jpg\".format(f\"{save_dir}/{video_id}\", index)\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    if not cv2.imwrite(filename, frame):\n",
    "                        print(\"failed save\")\n",
    "                    else:\n",
    "                        pass\n",
    "        cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
